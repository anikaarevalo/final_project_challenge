{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA_Mallet_Sentiment_Model_for_Amazon_Personal_Care_Appliances.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## FURTHER TEXT ANALYSIS OF AMAZON CUSTOMER REVIEW THROUGH TOPIC MODELLING"
      ],
      "metadata": {
        "id": "rb6t8NUJq88f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objectives of this test\n",
        "\n",
        "- Implement **Latent Dirichlet Allocation (LDA) from Gensim package** along with the Mallet’s implementation (via Gensim).\n",
        "\n",
        "- Implement **Mallet that optimizes LDA**. Mallet is known to run faster and gives better topic segregation.\n",
        "\n",
        "- Also **extract the volume and percentage contribution of each topic** to get an idea of how important a topic is."
      ],
      "metadata": {
        "id": "KwdJeqqxq9_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA PREPARATION"
      ],
      "metadata": {
        "id": "xVTSoaKJrMMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I. Installing libraries and dependencies"
      ],
      "metadata": {
        "id": "3IMl0FicryuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-requisites**: Downloading NLTK Dutch stopwords, data handling tools, model preprocessing & plotting tools, and SpaCy model"
      ],
      "metadata": {
        "id": "Mbs7rJ6KrnpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "B5GvRFhArF0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python data analysis tools and python module for printing\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "V3ChLWFMzoWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel"
      ],
      "metadata": {
        "id": "B5u8IHCqz3_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SpaCy for lemmatization\n",
        "import spacy"
      ],
      "metadata": {
        "id": "kCwcha5dz61g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting tools\n",
        "!pip install pyLDAvis\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gbpenH7Tz8xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignoring warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "y3kbabYZz-uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREPARING STOP WORDS** "
      ],
      "metadata": {
        "id": "APTof8NN0Aqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words ('english')"
      ],
      "metadata": {
        "id": "NXN5WNfy0GHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### II. Importing data set, exploratory data analysis, and preprocessing"
      ],
      "metadata": {
        "id": "0PfsD8El1DPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset that I am using is the **amazon personal care appliances reviews** which is a subset of the large Amazon Product review. The dataset is already stored in the **TensorFlow database** and can be loaded directly using the ‘tfds‘ API from Tensorflow.\n",
        "\n",
        "The dataset consists of reviews of **Amazon Personal_Care_Appliances_v1_00 products in US marketplace**."
      ],
      "metadata": {
        "id": "OMlpaA_T0lef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "ds = tfds.load('amazon_us_reviews/Personal_Care_Appliances_v1_00', split='train', shuffle_files=True)\n",
        "assert isinstance(ds, tf.data.Dataset)\n",
        "print(ds)"
      ],
      "metadata": {
        "id": "CD_7jjNZ0lpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting dataset into a pandas data frame using ‘tfds.as_dataframe‘ API.\n",
        "df = tfds.as_dataframe(ds)"
      ],
      "metadata": {
        "id": "fqw2aa-u1Kj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting a glimpse of the data frame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LkS28k_21LOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gettingt the number of rows and columns\n",
        "df.shape"
      ],
      "metadata": {
        "id": "BP6mKKpBspYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting useful information about the data frame\n",
        "# Note that the column containing the labels (i.e. 'star_rating') is integer in type\n",
        "df.info()"
      ],
      "metadata": {
        "id": "aP2RO-2_st3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting statistical information aboutt the data frame\n",
        "# Based on the count, mean, and max values, the data frame contains data that is normalised more or less\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "6xCPIhZas_GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPUTING 'SENTIMENT' AND 'SHORT_REVIEW' COLUMNS IN THE DATA FRAME**"
      ],
      "metadata": {
        "id": "lGL7C-ffyCry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **rating provided by the customer is on a scale of 1-5** ( 5 being the highest). As I am going to implement a binary classification model, I shall be converting these ratings into 2 categories, i.e 1 and 0. **Ratings above and equal to 3 will be labeled as Positive (1)** and **below 3 will be negative (0**). The following code will help us implement these steps."
      ],
      "metadata": {
        "id": "PbFJJeWHycUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'] = df['data/star_rating'].apply(lambda score: 'positive' if score >= 3 else 'negative')\n",
        "df['Sentiment'] = df['Sentiment'].map({'positive':1, 'negative':0})"
      ],
      "metadata": {
        "id": "-t6mLtwEyEo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['short_review'] =df['data/review_body'].str.decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "FJDjx2ueyvzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['short_review', 'Sentiment']]"
      ],
      "metadata": {
        "id": "wdewxRbAbqYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting a glimpse of the new data frame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2DXQg-tZzGlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "DZ5uuOH_zLsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISPLAYING NULL VALUES IF ANY IN ANY FEATURE**"
      ],
      "metadata": {
        "id": "Yhp6mdeczQ0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isna().sum()) "
      ],
      "metadata": {
        "id": "bq7OgY7izUSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###III. Data cleaning: Tokenization of text, removing stopwords, making bigrams & trigtrams, and lemmatizing"
      ],
      "metadata": {
        "id": "DmZa9AsTtkKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TOKENIZATION**"
      ],
      "metadata": {
        "id": "HI2mXGN0x8s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to list\n",
        "data = df.short_review.values.tolist()\n",
        "print(data[:1])"
      ],
      "metadata": {
        "id": "0wjDmJ2O1Ucq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing each sentence into a list of words, removing punctuations and unnecessary characters altogether.\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "metadata": {
        "id": "z1MeEt262JTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATING BIGRAMS AND TRIGRAMS**\n",
        "\n",
        "Bigrams are two (2) words frequently occurring together in the document. Trigrams are three (3) words frequently occurring."
      ],
      "metadata": {
        "id": "lP5ScZyD20yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ],
      "metadata": {
        "id": "Q_aCqHHj28YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seeing trigram example\n",
        "print(trigram_mod[bigram_mod[data_words]])"
      ],
      "metadata": {
        "id": "Vh_9U9U55hTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REMOVING STOPWORDS, MAKING BIGRAMS, TRIGRAMS, AND LEMMATIZATION**"
      ],
      "metadata": {
        "id": "lacNtcJat3I2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for text in texts:\n",
        "        doc = nlp(\" \".join(text)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])"
      ],
      "metadata": {
        "id": "VZ1xpsPX3DMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL TRAINING AND OPTIMISATION"
      ],
      "metadata": {
        "id": "u3C4XIbD1PsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###III. Initializing SpaCy's English NLP model (large size)"
      ],
      "metadata": {
        "id": "8s8k_aTd3Kh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOADING THE MODEL**"
      ],
      "metadata": {
        "id": "ZMTRg5-42CcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "#nlp = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "fXyQHcVZ3OgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CALLING THE FUNCTIONS IN ORDER**"
      ],
      "metadata": {
        "id": "qaUEHUjz3SdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Forming Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Loading the SpaCy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp = spacy.load('en_core_web_lg', disable=['parser', 'ner'])\n",
        "\n",
        "# Doing lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "#print(data_lemmatized)"
      ],
      "metadata": {
        "id": "CkCOrKS83Yi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_words_nostops[:1])"
      ],
      "metadata": {
        "id": "b9HVMoX75uXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_words_bigrams[:1])"
      ],
      "metadata": {
        "id": "USnNs18Z8OJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATING THE DICTIONARY AND CORPUS NEEDED FOR TOPIC MODELLING**"
      ],
      "metadata": {
        "id": "TqDlRLuK4j7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Creating Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# Viewing corpus\n",
        "#print(corpus)"
      ],
      "metadata": {
        "id": "JJbEvxml4lxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing corpus\n",
        "print(corpus[:1])"
      ],
      "metadata": {
        "id": "wcroB9Ms52io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
        "\n",
        "For example, (0, 1) above implies, word id 0 occurs once in the document. Likewise, word id 1 occurs once too, and so on.\n",
        "\n",
        "This is used as the input by the LDA model.\n",
        "\n",
        "If you want to see what word a given id corresponds to, pass the id as a key to the dictionary."
      ],
      "metadata": {
        "id": "UFBC440_4ruJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passing the id as a key to the dictionary to see what word a given ID corresponds to\n",
        "id2word[0]"
      ],
      "metadata": {
        "id": "4YZLl3hj4u0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus]"
      ],
      "metadata": {
        "id": "EJgwWjmt4vxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###IV. Defining and training the LDA model"
      ],
      "metadata": {
        "id": "T2rXMyV82Ld1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LDA model shall be built with 20 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic."
      ],
      "metadata": {
        "id": "Ymoz73gV42Jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "metadata": {
        "id": "8vHluvwO46b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VIEWING THE TOPICS IN THE LDA MODEL**"
      ],
      "metadata": {
        "id": "P1JJCBwo5Cvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing keywords for 20 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "metadata": {
        "id": "kzYt9TCP5Efn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**:\n",
        "\n",
        "The weights reflect how important a keyword is to that topic.\n",
        "\n",
        "Looking at these keywords, you can guess what this topic could be."
      ],
      "metadata": {
        "id": "g8xpAcrq5MFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COMPUTE MODEL PERPLEXITY AND COHERENCE SCORE**"
      ],
      "metadata": {
        "id": "izLEn2GE2u06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model perplexity** and **topic coherence** provide a convenient measure to judge how good a given topic model is."
      ],
      "metadata": {
        "id": "P_CVU9FC5O32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Computing Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "id": "EY0yaqkA5T-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLOT: VISUALISING TOPIC-KEYWORDS DISTRIBUTION**"
      ],
      "metadata": {
        "id": "voWFc_y-5kdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feeding the model into the pyLDAvis instance\n",
        "vis_1 = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "vis_1\n"
      ],
      "metadata": {
        "id": "gHVb-xER5ngO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to make inferences from pyLDAvis' output**:\n",
        "\n",
        "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
        "\n",
        "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
        "\n",
        "A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
        "\n",
        "Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic."
      ],
      "metadata": {
        "id": "ahdFJke85qG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model optimisation: Mallet's version of LDA**"
      ],
      "metadata": {
        "id": "vW2oGRR55veI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up next, we will improve upon this model by using Mallet’s version of LDA algorithm and then we will focus on how to arrive at the optimal number of topics given any large corpus of text.\n",
        "\n",
        "Gensim provides a wrapper to implement Mallet’s LDA from within Gensim itself."
      ],
      "metadata": {
        "id": "gLnAZ1-453-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrading Gensim\n",
        "# Updated to enforce Gensim v3.8 in Colab (the last version to support running topic models via Mallet).\n",
        "# https://github.com/polsci/colab-gensim-mallet\n",
        "!pip3 install --upgrade gensim==3.8"
      ],
      "metadata": {
        "id": "EWkgwPUb5xgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Mallet\n",
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "!unzip mallet-2.0.8.zip"
      ],
      "metadata": {
        "id": "XqCrsaS06C8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###V. Implementing LDA optimisation from within base model"
      ],
      "metadata": {
        "id": "1IEVxsGR4lBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mallet_path = 'mallet-2.0.8/bin/mallet'\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "metadata": {
        "id": "MejI_sBk6FKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing Topics\n",
        "pprint(ldamallet.show_topics(formatted=False))"
      ],
      "metadata": {
        "id": "qa0uBB3W6Z17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "metadata": {
        "id": "U_Uq0sor6diJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**: A remarkable increase in coherence score"
      ],
      "metadata": {
        "id": "7OZ2sKokGiQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VI. Fine-tuning and saving the optimised LDA model"
      ],
      "metadata": {
        "id": "ycpjAOMSG9pS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mallet_model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet, gamma_threshold=0.001, iterations=50)"
      ],
      "metadata": {
        "id": "LwqIi9MMGrXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import datapath\n",
        "\n",
        "# Save model to disk.\n",
        "\n",
        "temp_file = datapath('drive/MyDrive/models/mallet')\n",
        "\n",
        "mallet_model.save(temp_file)"
      ],
      "metadata": {
        "id": "04RaVpF9GuRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PLOT: OPTIMISED TOPIC-KEYWORDS DISTRIBUTION**"
      ],
      "metadata": {
        "id": "SoGPvo2hG2Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feeding the model into the pyLDAvis instance\n",
        "\n",
        "vis_2 = gensimvis.prepare(mallet_model, corpus, id2word)\n",
        "vis_2"
      ],
      "metadata": {
        "id": "Pbh0MabZ6RvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FINDING THE OPTIMAL NUMBER OF TOPICS OF THE LDA MODEL**"
      ],
      "metadata": {
        "id": "ICchl9833bqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The approach to finding the optimal number of topics is to build many LDA models with different values of number of topics (k) and pick the one that gives the highest coherence value."
      ],
      "metadata": {
        "id": "bfe84-2T6k2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "    \n",
        "    return model_list, coherence_values"
      ],
      "metadata": {
        "id": "3KaeiUgR6-_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can take a long time to run.\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)\n"
      ],
      "metadata": {
        "id": "b3yyZhSX7IMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing graph\n",
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BJybRvX37KS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<NOTE: The optimal coherence score shown in this plot lies around 14 number of topics.**>"
      ],
      "metadata": {
        "id": "6MZk3wrq7Qwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "metadata": {
        "id": "__1sh4Zj7rGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the coherence score seems to keep increasing, it may make better sense to pick the model that gave the highest CV before flattening out."
      ],
      "metadata": {
        "id": "_g6koXVa7sU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<**CHOOSING THE MODEL WITH, , () TOPICS**>"
      ],
      "metadata": {
        "id": "q-N7ydJu7xXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the model and print the topics\n",
        "# The best LDA model with the optimal coherence score has 14 topics, which is\n",
        "# index 2 from the model_list list\n",
        "optimal_model = model_list[2]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "metadata": {
        "id": "Vt6XeiOy7veP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FINAL MODEL**"
      ],
      "metadata": {
        "id": "qFHlMNfoHdo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(optimal_model, gamma_threshold=0.001, iterations=50)"
      ],
      "metadata": {
        "id": "I2vkfepDHa_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VISUALISING FINAL MODEL**"
      ],
      "metadata": {
        "id": "SEUcGkIVHoZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vis_3 = gensimvis.prepare(final_model, corpus, id2word)\n",
        "vis_3"
      ],
      "metadata": {
        "id": "68gkZ6a8HrOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FINDING THE DOMINANT TOPIC IN EACH SENTENCE**"
      ],
      "metadata": {
        "id": "VQ1OH7iO3q4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the practical application of topic modeling is to determine what topic a given document is about.\n",
        "\n",
        "To find that, we find the topic number that has the **highest percentage contribution in the data set**."
      ],
      "metadata": {
        "id": "3bCyOHbB75To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_words):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data_words)"
      ],
      "metadata": {
        "id": "EQnOVlh78AVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Formatting\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Showing\n",
        "df_dominant_topic.head(10)"
      ],
      "metadata": {
        "id": "qtuym7F18CPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FINDING THE MOST REPRESENTATIVE DOCUMENT FOR EACH TOPIC**"
      ],
      "metadata": {
        "id": "Q3vtHoWW3uHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With understanding the topic, you can find the documents a given topic has contributed to the most and infer the topic by reading that document."
      ],
      "metadata": {
        "id": "T9paDZTW8GLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping the top 5 sentences under each topic\n",
        "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
        "                                            axis=0)\n",
        "\n",
        "# Reseting Index    \n",
        "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Formating\n",
        "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "# Showing\n",
        "sent_topics_sorteddf_mallet.head()"
      ],
      "metadata": {
        "id": "0bhmlrf48IhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tabular output above actually has 20 rows, one each for a topic. It has the topic number, the keywords, and the most representative document. The **Perc_Contribution column** is nothing but the percentage contribution of the topic in the given document."
      ],
      "metadata": {
        "id": "OcbjeeEC8Pz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TOPIC DISTRIBUTION ACROSS DOCUMENTS**"
      ],
      "metadata": {
        "id": "KrkhcZJV37SJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we want to understand the volume and distribution of topics in order to judge how widely it was discussed."
      ],
      "metadata": {
        "id": "mwRx5qAY8Yml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Documents for Each Topic\n",
        "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
        "\n",
        "# Percentage of Documents for Each Topic\n",
        "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
        "\n",
        "# Topic Number and Keywords\n",
        "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
        "\n",
        "# Concatenatinate Column wise\n",
        "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
        "\n",
        "# Change Column names\n",
        "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
        "\n",
        "# Show\n",
        "df_dominant_topics[:20]"
      ],
      "metadata": {
        "id": "kjXQ1bt78aQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EVALUATION"
      ],
      "metadata": {
        "id": "edYcPvwD4C-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###VII. Predicting results"
      ],
      "metadata": {
        "id": "FAMIVZVk4F_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import gensim.corpora as corpora\n",
        "from gensim.test.utils import datapath\n",
        "from gensim.models import LdaModel\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "h0U5t_paIJtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "y4GHit3kIKad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = datapath('drive/MyDrive/models/mallet')\n",
        "\n",
        "model = LdaModel.load(path)\n",
        "\n",
        "pattern = r'\\\"([\\w]*)\\\"'\n",
        "pat = re.compile(pattern)\n",
        "topics = {}\n",
        "for topic in model.print_topics():\n",
        "    new_text = pat.findall(topic[1])\n",
        "    topics[topic[0]] = new_text"
      ],
      "metadata": {
        "id": "DMvQwxBgIMc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics_df = pd.Series(topics, name='keywords')\n",
        "topics_df"
      ],
      "metadata": {
        "id": "rnDPk2s74P4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RE33cA3-Iuu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = joblib.load('./models/corpus')\n",
        "\n",
        "common_corpus = corpora.dictionary.Dictionary(corpus)"
      ],
      "metadata": {
        "id": "yBI0EH90Iojb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feeding the model into the pyLDAvis instance\n",
        "vis_4 = gensimvis.prepare(model, [common_corpus.doc2bow(text) for text in corpus], common_corpus)\n",
        "vis_4"
      ],
      "metadata": {
        "id": "uBFSoGvBI2Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''\n",
        "I've been painfully plucking my chin hairs and lady moustache for years. This thing does wonders!! The blade is close enough to \n",
        "get a smooth shave, and it also has a protector so it doesn't cut your skin. Easy to use; MUCH faster than plucking; and less \n",
        "painful than waxing and plucking. Would definitely recommend!!\n",
        "'''"
      ],
      "metadata": {
        "id": "QB73WCYOJHUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from preprocess import preproces"
      ],
      "metadata": {
        "id": "OFmDb9edJuyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_text = preproces([text])\n",
        "new_corpus = [common_corpus.doc2bow(text) for text in lemmatized_text]"
      ],
      "metadata": {
        "id": "pGEOlZmhJvV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {}\n",
        "for score in model[new_corpus[0]]:\n",
        "    scores[score[0]] = np.round(score[1],3)\n",
        "score_df =pd.Series(scores, name='score')\n",
        "topics_df = pd.Series(topics, name='keywords')\n",
        "df = pd.concat([score_df, topics_df], axis=1)\n",
        "df.index.name = 'topic'\n",
        "df_final = df.sort_values(by='score', ascending=False)"
      ],
      "metadata": {
        "id": "GHCxI7r6Jy2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final[:10]"
      ],
      "metadata": {
        "id": "PGys_c7RJ0xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_final.to_csv('./data/file.csv')"
      ],
      "metadata": {
        "id": "zbWelxvFJ-OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONCLUSION"
      ],
      "metadata": {
        "id": "CRaNEi3N8civ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From all Dutch legal text files that were cleaned, further ML preprocessing and unsupervised topic extraction were carried out via:\n",
        "\n",
        "- A basic topic model using Gensim’s LDA;\n",
        "\n",
        "- pyLDAvis for topic visualisation; and\n",
        "\n",
        "- Mallet’s LDA implementation."
      ],
      "metadata": {
        "id": "emWGcDLirStN"
      }
    }
  ]
}