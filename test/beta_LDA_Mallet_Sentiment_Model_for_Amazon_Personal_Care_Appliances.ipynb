{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA_Mallet_Sentiment_Model_for_Amazon_Personal_Care_Appliances.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Further text preprocessing"
      ],
      "metadata": {
        "id": "rb6t8NUJq88f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objectives of this test\n",
        "\n",
        "- Implement Latent Dirichlet Allocation (LDA) from Gensim package along with the Mallet’s implementation (via Gensim).\n",
        "\n",
        "- Implement Mallet that optimizes LDA. Mallet is known to run faster and gives better topic segregation.\n",
        "\n",
        "- Also extract the volume and percentage contribution of each topic to get an idea of how important a topic is."
      ],
      "metadata": {
        "id": "KwdJeqqxq9_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-requisites: Downloading NLTK Dutch stopwords, data handling tools, model preprocessing & plotting tools, and SpaCy model"
      ],
      "metadata": {
        "id": "xVTSoaKJrMMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "B5GvRFhArF0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK\n",
        "import nltk\n",
        "nltk.download('stopwords', 'dutch')"
      ],
      "metadata": {
        "id": "P96XdS9Qzno_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python data analysis tools and python module for printing\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "V3ChLWFMzoWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel"
      ],
      "metadata": {
        "id": "B5u8IHCqz3_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SpaCy for lemmatization\n",
        "import spacy"
      ],
      "metadata": {
        "id": "kCwcha5dz61g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting tools\n",
        "!pip install pyLDAvis\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gbpenH7Tz8xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignoring warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "y3kbabYZz-uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing stopwords"
      ],
      "metadata": {
        "id": "APTof8NN0Aqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK Stop words\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "NXN5WNfy0GHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data set"
      ],
      "metadata": {
        "id": "0PfsD8El1DPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset that I am using is the **amazon personal care appliances reviews** which is a subset of the large Amazon Product review. The dataset is already stored in the **TensorFlow database** and can be loaded directly using the ‘tfds‘ API from Tensorflow.\n",
        "\n",
        "The dataset consists of reviews of **Amazon Personal_Care_Appliances_v1_00 products in US marketplace**."
      ],
      "metadata": {
        "id": "OMlpaA_T0lef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "ds = tfds.load('amazon_us_reviews/Personal_Care_Appliances_v1_00', split='train', shuffle_files=True)\n",
        "assert isinstance(ds, tf.data.Dataset)\n",
        "print(ds)"
      ],
      "metadata": {
        "id": "CD_7jjNZ0lpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting dataset into a pandas data frame using ‘tfds.as_dataframe‘ API.\n",
        "df = tfds.as_dataframe(ds)"
      ],
      "metadata": {
        "id": "fqw2aa-u1Kj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting a glimpse of the data frame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LkS28k_21LOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning-up text and Tokenizing Words\n",
        "\n",
        "I'll tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether.\n",
        "\n",
        "**Gensim’s simple_preprocess()** is great for this. Additionally I have set deacc=True to remove the punctuations"
      ],
      "metadata": {
        "id": "1kyoNPth1US4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to list\n",
        "data = df.content.values.tolist()\n",
        "\n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "\n",
        "#pprint(data[:1])"
      ],
      "metadata": {
        "id": "0wjDmJ2O1Ucq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing each sentence into a list of words, removing punctuations and unnecessary characters altogether.\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "#print(data_words)"
      ],
      "metadata": {
        "id": "z1MeEt262JTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating bigrams and trigrams\n",
        "\n",
        "Bigrams are two (2) words frequently occurring together in the document. Trigrams are three (3) words frequently occurring."
      ],
      "metadata": {
        "id": "lP5ScZyD20yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# Seeing trigram example\n",
        "#print(trigram_mod[bigram_mod[data_words]])"
      ],
      "metadata": {
        "id": "Q_aCqHHj28YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing stopwords, making bigrams & trigtrams, and lemmatizing"
      ],
      "metadata": {
        "id": "z6X_N0ZK2-Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])"
      ],
      "metadata": {
        "id": "VZ1xpsPX3DMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing SpaCy's English NLP model (large size)"
      ],
      "metadata": {
        "id": "8s8k_aTd3Kh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "#nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "fXyQHcVZ3OgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calling the functions in order"
      ],
      "metadata": {
        "id": "qaUEHUjz3SdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Forming Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Loading the SpaCy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp = spacy.load('nl_core_web_lg', disable=['parser', 'ner'])\n",
        "\n",
        "# Doing lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "#print(data_lemmatized)"
      ],
      "metadata": {
        "id": "CkCOrKS83Yi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Dictionary and Corpus needed for Topic Modeling"
      ],
      "metadata": {
        "id": "TqDlRLuK4j7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Creating Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# Viewing corpus\n",
        "#print(corpus)"
      ],
      "metadata": {
        "id": "JJbEvxml4lxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
        "\n",
        "For example, (0, 1) above implies, word id 0 occurs once in the document. Likewise, word id 1 occurs once too, and so on.\n",
        "\n",
        "This is used as the input by the LDA model.\n",
        "\n",
        "If you want to see what word a given id corresponds to, pass the id as a key to the dictionary."
      ],
      "metadata": {
        "id": "UFBC440_4ruJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passing the id as a key to the dictionary to see what word a given ID corresponds to\n",
        "id2word[0]"
      ],
      "metadata": {
        "id": "4YZLl3hj4u0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus]"
      ],
      "metadata": {
        "id": "EJgwWjmt4vxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Building the topic model\n",
        "\n",
        "The LDA model shall be built with 20 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic."
      ],
      "metadata": {
        "id": "Ymoz73gV42Jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "metadata": {
        "id": "8vHluvwO46b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing the topics in LDA model"
      ],
      "metadata": {
        "id": "P1JJCBwo5Cvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing keywords for 20 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "metadata": {
        "id": "kzYt9TCP5Efn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**:\n",
        "\n",
        "The weights reflect how important a keyword is to that topic.\n",
        "\n",
        "Looking at these keywords, you can guess what this topic could be."
      ],
      "metadata": {
        "id": "g8xpAcrq5MFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Model Perplexity and Coherence Score\n",
        "\n",
        "**Model perplexity** and **topic coherence** provide a convenient measure to judge how good a given topic model is."
      ],
      "metadata": {
        "id": "P_CVU9FC5O32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Computing Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "id": "EY0yaqkA5T-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing topic-keywords distribution"
      ],
      "metadata": {
        "id": "voWFc_y-5kdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feeding the model into the pyLDAvis instance\n",
        "vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "vis\n"
      ],
      "metadata": {
        "id": "gHVb-xER5ngO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to make inferences from pyLDAvis' output**:\n",
        "\n",
        "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
        "\n",
        "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
        "\n",
        "A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
        "\n",
        "Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic."
      ],
      "metadata": {
        "id": "ahdFJke85qG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mallet's version of LDA"
      ],
      "metadata": {
        "id": "vW2oGRR55veI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up next, we will improve upon this model by using Mallet’s version of LDA algorithm and then we will focus on how to arrive at the optimal number of topics given any large corpus of text.\n",
        "\n",
        "Gensim provides a wrapper to implement Mallet’s LDA from within Gensim itself."
      ],
      "metadata": {
        "id": "gLnAZ1-453-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upgrading Gensim\n",
        "# Updated to enforce Gensim v3.8 in Colab (the last version to support running topic models via Mallet).\n",
        "# https://github.com/polsci/colab-gensim-mallet\n",
        "!pip3 install --upgrade gensim==3.8"
      ],
      "metadata": {
        "id": "EWkgwPUb5xgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Mallet\n",
        "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "!unzip mallet-2.0.8.zip"
      ],
      "metadata": {
        "id": "XqCrsaS06C8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mallet_path = 'mallet-2.0.8/bin/mallet'\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
      ],
      "metadata": {
        "id": "MejI_sBk6FKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing Topics\n",
        "pprint(ldamallet.show_topics(formatted=False))"
      ],
      "metadata": {
        "id": "qa0uBB3W6Z17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "metadata": {
        "id": "U_Uq0sor6diJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<NOTE: A remarkable increase in coherence score from 0.4801422476656797 to 0.5182866140021632.>** "
      ],
      "metadata": {
        "id": "1M8U9MEL6gS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the optimal number of topics for LDA\n",
        "\n",
        "The approach to finding the optimal number of topics is to build many LDA models with different values of number of topics (k) and pick the one that gives the highest coherence value."
      ],
      "metadata": {
        "id": "bfe84-2T6k2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "    \n",
        "    return model_list, coherence_values"
      ],
      "metadata": {
        "id": "3KaeiUgR6-_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Can take a long time to run.\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)\n"
      ],
      "metadata": {
        "id": "b3yyZhSX7IMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing graph\n",
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BJybRvX37KS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<NOTE: The optimal coherence score shown in this plot lies around 14 number of topics.**>"
      ],
      "metadata": {
        "id": "6MZk3wrq7Qwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "metadata": {
        "id": "__1sh4Zj7rGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the coherence score seems to keep increasing, it may make better sense to pick the model that gave the highest CV before flattening out."
      ],
      "metadata": {
        "id": "_g6koXVa7sU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <Choosing the model with fourteen (14) topics>"
      ],
      "metadata": {
        "id": "q-N7ydJu7xXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the model and print the topics\n",
        "# The best LDA model with the optimal coherence score has 14 topics, which is\n",
        "# index 2 from the model_list list\n",
        "optimal_model = model_list[2]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "metadata": {
        "id": "Vt6XeiOy7veP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the dominant topic in each sentence\n",
        "\n",
        "One of the practical application of topic modeling is to determine what topic a given document is about.\n",
        "\n",
        "To find that, we find the topic number that has the **highest percentage contribution in the data set**."
      ],
      "metadata": {
        "id": "3bCyOHbB75To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_words):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data_words)"
      ],
      "metadata": {
        "id": "EQnOVlh78AVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Formatting\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Showing\n",
        "df_dominant_topic.head(10)"
      ],
      "metadata": {
        "id": "qtuym7F18CPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the most representative document for each topic\n",
        "\n",
        "With understanding the topic, you can find the documents a given topic has contributed to the most and infer the topic by reading that document."
      ],
      "metadata": {
        "id": "T9paDZTW8GLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping the top 5 sentences under each topic\n",
        "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
        "\n",
        "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
        "\n",
        "for i, grp in sent_topics_outdf_grpd:\n",
        "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
        "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
        "                                            axis=0)\n",
        "\n",
        "# Reseting Index    \n",
        "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Formating\n",
        "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
        "\n",
        "# Showing\n",
        "sent_topics_sorteddf_mallet.head()"
      ],
      "metadata": {
        "id": "0bhmlrf48IhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tabular output above actually has 20 rows, one each for a topic. It has the topic number, the keywords, and the most representative document. The **Perc_Contribution column** is nothing but the percentage contribution of the topic in the given document."
      ],
      "metadata": {
        "id": "OcbjeeEC8Pz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Topic distribution across documents\n",
        "\n",
        "Finally, we want to understand the volume and distribution of topics in order to judge how widely it was discussed."
      ],
      "metadata": {
        "id": "mwRx5qAY8Yml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of Documents for Each Topic\n",
        "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
        "\n",
        "# Percentage of Documents for Each Topic\n",
        "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
        "\n",
        "# Topic Number and Keywords\n",
        "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
        "\n",
        "# Concatenatinate Column wise\n",
        "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
        "\n",
        "# Change Column names\n",
        "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
        "\n",
        "# Show\n",
        "df_dominant_topics"
      ],
      "metadata": {
        "id": "kjXQ1bt78aQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONCLUSION"
      ],
      "metadata": {
        "id": "CRaNEi3N8civ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "From all Dutch legal text files that were cleaned, further ML preprocessing and unsupervised topic extraction were carried out via:\n",
        "\n",
        "- A basic topic model using Gensim’s LDA;\n",
        "\n",
        "- pyLDAvis for topic visualisation; and\n",
        "\n",
        "- Mallet’s LDA implementation."
      ],
      "metadata": {
        "id": "diOnChnn8eOm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}