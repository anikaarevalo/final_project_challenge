{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "27jun_short_demo.sentment_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Description:"
      ],
      "metadata": {
        "id": "WKpfyMBjkySo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The purpose of this simple demo is to show that **my re-trained transformer NLP model, a pre-trained DistilBERT, is a MVP** that analyses and predicts with remarkable accuracy between a positive and a negative customer review. \n",
        "\n",
        "- **TFDistilBertForSequenceClassification** was configured to train, test, & validate on a data frame of approximately **85,981 data points**. The **training data set consisted 30% of this**. \n",
        "\n",
        "- To **evaluate the model, I shall pass unseen new data** into it in the form of sample reviews. The sample reviews are taken from actual Amazon (US)personal care appliances reviews: **test_review1 is a positive review** while **test_review2 is a negative review**. "
      ],
      "metadata": {
        "id": "7dFBFQUvmYaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I. Installing libraries and dependencies"
      ],
      "metadata": {
        "id": "N2OOb-Ygn4eL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Native Python machine learning module**"
      ],
      "metadata": {
        "id": "gyWq4a-9oU_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "6np7HItAn6Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activating GPU of Google Colab needed to run a large-sized ML Model**"
      ],
      "metadata": {
        "id": "EmVsDA7hodx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_gpus_available = len(tf.config.experimental.list_physical_devices('GPU'))\n",
        "print('Num GPUs Available: ', num_gpus_available) \n",
        "assert num_gpus_available > 0"
      ],
      "metadata": {
        "id": "8-mFnCZ3n_LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87409674-1c27-41fb-af73-3a0b31de2956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing API from Hugging Face**"
      ],
      "metadata": {
        "id": "_Ma8WzdnoyuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers"
      ],
      "metadata": {
        "id": "bUCghjuVoCuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing modules for NLP tasks**"
      ],
      "metadata": {
        "id": "JpkH_E-Bo5Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import TFDistilBertForSequenceClassification"
      ],
      "metadata": {
        "id": "vosRm3YToPfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###II. Implementing Tokenizer from DistilBertTokenizerFast "
      ],
      "metadata": {
        "id": "8P3cdgzuo9Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')"
      ],
      "metadata": {
        "id": "R4NyD4HOpLjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###III. Retrieving the re-trained model"
      ],
      "metadata": {
        "id": "pCWl-t2ypWb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Google Drive to access saved model**"
      ],
      "metadata": {
        "id": "3qZ0bNqBpiRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tBGMxFQOpc0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e7da43-3271-4fe8-96f0-ccd88f41fb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the model**"
      ],
      "metadata": {
        "id": "iZjXvYBsp2vJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = TFDistilBertForSequenceClassification.from_pretrained('drive/MyDrive/tdb_sentiment')"
      ],
      "metadata": {
        "id": "Q2PAXICapsX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988d4aa5-ebb0-4b4f-b9e7-08e03a6006ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
            "\n",
            "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at drive/MyDrive/tdb_sentiment.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IV. Predicting on unseen data"
      ],
      "metadata": {
        "id": "t-kCjIE6p5Yq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive review**"
      ],
      "metadata": {
        "id": "IyeX26i8qGyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A 5-star rating from https://www.amazon.com/Philips-PrecisionPerfect-Precision-HP6390-51/dp/B00I471M9E/ref=lp_17395279011_1_8#customerReviews\n",
        "test_review1 = '''    \n",
        "I've been painfully plucking my chin hairs \n",
        "and lady moustache for years. This thing does \n",
        "wonders!! The blade is close enough to get a smooth \n",
        "shave, and it also has a protector so it doesn't cut your \n",
        "skin. Easy to use; MUCH faster than plucking; and less \n",
        "painful than waxing and plucking. Would definitely recommend!!\n",
        "'''\n",
        "\n",
        "predict_input = tokenizer.encode(test_review1,\n",
        "                                 truncation=True,\n",
        "                                 padding=True,\n",
        "                                 return_tensors='tf')\n",
        "tf_output = loaded_model.predict(predict_input)[0]\n",
        "tf_prediction = tf.nn.softmax(tf_output, axis=1)  # Activation set to softmax for Sparse Categorical Entropy loss\n",
        "labels = ['Negative','Positive']\n",
        "label = tf.argmax(tf_prediction, axis=1)\n",
        "label = label.numpy()\n",
        "print(labels[label[0]])"
      ],
      "metadata": {
        "id": "D3HygdtHqBGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3130cd-0ec8-4e70-adcb-d79d683de6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Negative review**"
      ],
      "metadata": {
        "id": "4wO11q8dqV6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A 1-star rating from https://www.amazon.com/product-reviews/B00I471M9E/ref=acr_dp_hist_1?ie=UTF8&filterByStar=one_star&reviewerType=all_reviews#reviews-filter-bar\n",
        "test_review2 = '''\n",
        "This product lasted about 4 months - thought the battery was bad \n",
        "so I replaced it and it still didn’t work - it was dead ! I used it \n",
        "a total of 3 times !!! Had to toss , would not buy again ... I’m going \n",
        "back to my old school methods of using a scissor and a comb ...\n",
        "'''\n",
        "\n",
        "predict_input = tokenizer.encode(test_review2,\n",
        "                                 truncation=True,\n",
        "                                 padding=True,\n",
        "                                 return_tensors='tf')\n",
        "tf_output = loaded_model.predict(predict_input)[0]\n",
        "tf_prediction = tf.nn.softmax(tf_output, axis=1)  # Activation set to softmax for Sparse Categorical Entropy loss\n",
        "labels = ['Negative','Positive']\n",
        "label = tf.argmax(tf_prediction, axis=1)\n",
        "label = label.numpy()\n",
        "print(labels[label[0]])"
      ],
      "metadata": {
        "id": "_xJkQzLZqPjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25190265-64a7-4981-8bfe-d6436b70273d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ]
    }
  ]
}