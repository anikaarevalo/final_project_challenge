{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz5lJECYbyhw"
      },
      "source": [
        "**I. Installing machine learning and NLP libraries and dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiF-MqRhb0GH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "num_gpus_available = len(tf.config.experimental.list_physical_devices('GPU'))\n",
        "assert num_gpus_available > 0\n",
        "!pip3 install transformers\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import TFDistilBertForSequenceClassification\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)  # Ignoring warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSCnRqxyeHEM"
      },
      "source": [
        "**II. A function that predicts label (positive or negative) when user inputs according to the parameters of the TFDistilBertForSequenceClassification model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AptTSzDScak9"
      },
      "outputs": [],
      "source": [
        "def predict_label(client_review):    \n",
        "    # Initializing a tokenizer\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
        "    # Loading the saved re-trained, pre-trained DistilBert NLP model\n",
        "    loaded_model = TFDistilBertForSequenceClassification.from_pretrained('drive/MyDrive/tdb_sentiment')\n",
        "\n",
        "    # Predicting on unseen/new data\n",
        "    predict_input = tokenizer.encode(client_review,\n",
        "                                    truncation=True, \n",
        "                                    padding=True, \n",
        "                                    return_tensors='tf')\n",
        "    tf_output = loaded_model.predict(predict_input)[0]\n",
        "    tf_prediction = tf.nn.softmax(tf_output, axis=1)  # Activation set to softmax for Sparse Categorical Entropy loss\n",
        "    labels = ['Negative','Positive']\n",
        "    label = tf.argmax(tf_prediction, axis=1)\n",
        "    label = label.numpy()\n",
        "    \n",
        "    # Returning prediction of label (postive or negative)\n",
        "    return labels[label[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJC-9IRSe1RP"
      },
      "source": [
        "**III. Sample new input for model prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1K99srQdtc2"
      },
      "outputs": [],
      "source": [
        "client_review = '''    \n",
        "I've been painfully plucking my chin hairs \n",
        "and lady moustache for years. This thing does \n",
        "wonders!! The blade is close enough to get a smooth \n",
        "shave, and it also has a protector so it doesn't cut your \n",
        "skin. Easy to use; MUCH faster than plucking; and less \n",
        "painful than waxing and plucking. Would definitely recommend!!\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxlSNr4Men8L"
      },
      "source": [
        "**IV. Calling the prediction of the label (positive or negative) after user data is put in in the form of a numpy array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "V_f6461vdxUp",
        "outputId": "966ed489-00a3-4dcb-d533-b6b941a55080"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at drive/MyDrive/tdb_sentiment were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/tdb_sentiment and are newly initialized: ['dropout_119']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58a4456a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_label(client_review)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "predict_function.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
